{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "789f7e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras import callbacks\n",
    "import keras_tuner as kt\n",
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc1713c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('grid.csv')\n",
    "\n",
    "dataset['stabf'] = dataset['stabf'].replace({'unstable': 0, 'stable': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aca7944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.959060</td>\n",
       "      <td>3.079885</td>\n",
       "      <td>8.381025</td>\n",
       "      <td>9.780754</td>\n",
       "      <td>3.763085</td>\n",
       "      <td>-0.782604</td>\n",
       "      <td>-1.257395</td>\n",
       "      <td>-1.723086</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.859578</td>\n",
       "      <td>0.887445</td>\n",
       "      <td>0.958034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.304097</td>\n",
       "      <td>4.902524</td>\n",
       "      <td>3.047541</td>\n",
       "      <td>1.369357</td>\n",
       "      <td>5.067812</td>\n",
       "      <td>-1.940058</td>\n",
       "      <td>-1.872742</td>\n",
       "      <td>-1.255012</td>\n",
       "      <td>0.413441</td>\n",
       "      <td>0.862414</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.781760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.971707</td>\n",
       "      <td>8.848428</td>\n",
       "      <td>3.046479</td>\n",
       "      <td>1.214518</td>\n",
       "      <td>3.405158</td>\n",
       "      <td>-1.207456</td>\n",
       "      <td>-1.277210</td>\n",
       "      <td>-0.920492</td>\n",
       "      <td>0.163041</td>\n",
       "      <td>0.766689</td>\n",
       "      <td>0.839444</td>\n",
       "      <td>0.109853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.716415</td>\n",
       "      <td>7.669600</td>\n",
       "      <td>4.486641</td>\n",
       "      <td>2.340563</td>\n",
       "      <td>3.963791</td>\n",
       "      <td>-1.027473</td>\n",
       "      <td>-1.938944</td>\n",
       "      <td>-0.997374</td>\n",
       "      <td>0.446209</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>0.362718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.134112</td>\n",
       "      <td>7.608772</td>\n",
       "      <td>4.943759</td>\n",
       "      <td>9.857573</td>\n",
       "      <td>3.525811</td>\n",
       "      <td>-1.125531</td>\n",
       "      <td>-1.845975</td>\n",
       "      <td>-0.554305</td>\n",
       "      <td>0.797110</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>0.820923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0  2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n",
       "1  9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n",
       "2  8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n",
       "3  0.716415  7.669600  4.486641  2.340563  3.963791 -1.027473 -1.938944   \n",
       "4  3.134112  7.608772  4.943759  9.857573  3.525811 -1.125531 -1.845975   \n",
       "\n",
       "         p4        g1        g2        g3        g4  \n",
       "0 -1.723086  0.650456  0.859578  0.887445  0.958034  \n",
       "1 -1.255012  0.413441  0.862414  0.562139  0.781760  \n",
       "2 -0.920492  0.163041  0.766689  0.839444  0.109853  \n",
       "3 -0.997374  0.446209  0.976744  0.929381  0.362718  \n",
       "4 -0.554305  0.797110  0.455450  0.656947  0.820923  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = dataset.drop('stab', axis = 1)\n",
    "y = X.pop('stabf')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle =True, test_size=0.3, random_state=42)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "802b5771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp_model = Sequential(\n",
    "#     [\n",
    "#         Dense(24 ,input_dim = 12, activation='relu'),\n",
    "#         Dense(24 , activation='relu'),\n",
    "#         Dense(24 , activation='relu'),\n",
    "#         Dense(12 , activation='relu'),\n",
    "#         Dense(1 , activation='sigmoid')\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# mlp_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "239acee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta=0.001, # minimium amount of change to count as an improvement\n",
    "    patience=20, # n epochs before stopping\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "# mlp_model.fit(X_train,y_train,epochs = 150, callbacks=[early_stopping],validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31426177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# y_pred = mlp_model.predict(X_test)\n",
    "# y_pred = (y_pred > 0.5)\n",
    "\n",
    "# report = classification_report(y_test,y_pred, output_dict = True)\n",
    "# cr = pd.DataFrame(report).transpose()\n",
    "# print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aefd33a",
   "metadata": {},
   "source": [
    "# Hyper Param Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01ee5126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    hp_units = hp.Int('units', min_value=12, max_value=192, step=12)\n",
    "    hp_dropout = hp.Choice('dropout', values=[0.0, 0.1, 0.2, 0.3])\n",
    "    \n",
    "    model = Sequential([\n",
    "    Dense(units=hp_units ,input_dim = 12, activation='relu'),\n",
    "    Dense(units=hp_units , activation='relu'),\n",
    "    Dropout(hp_dropout, seed=42),\n",
    "    Dense(units=hp_units , activation='relu'),\n",
    "    Dense(units=hp_units , activation='relu'),\n",
    "    Dropout(hp_dropout, seed=42),\n",
    "    Dense(units=hp_units , activation='relu'),\n",
    "    Dense(units=hp_units , activation='relu'),\n",
    "    Dropout(hp_dropout, seed=42),\n",
    "    Dense(units=hp_units , activation='relu'),\n",
    "    Dense(units=hp_units , activation='relu'),\n",
    "    Dropout(hp_dropout, seed=42),\n",
    "    Dense(units=hp_units , activation='relu'),\n",
    "    Dense(units=hp_units/2 , activation='relu'),\n",
    "    Dense(1 , activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4, 1e-5])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=hp_learning_rate),\n",
    "                loss=BinaryCrossentropy(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdf17d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project .\\untitled_project\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from .\\untitled_project\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=300,)\n",
    "\n",
    "# tuner.search(X_train, y_train, epochs=150, validation_split=0.2, callbacks=[early_stopping])\n",
    "tuner.reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b86d1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1050/1050 [==============================] - 3s 2ms/step - loss: 0.3249 - accuracy: 0.8532 - val_loss: 0.2008 - val_accuracy: 0.9189\n",
      "Epoch 2/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1784 - accuracy: 0.9244 - val_loss: 0.1593 - val_accuracy: 0.9373\n",
      "Epoch 3/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1457 - accuracy: 0.9372 - val_loss: 0.1778 - val_accuracy: 0.9195\n",
      "Epoch 4/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1332 - accuracy: 0.9451 - val_loss: 0.1122 - val_accuracy: 0.9531\n",
      "Epoch 5/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1280 - accuracy: 0.9474 - val_loss: 0.1291 - val_accuracy: 0.9475\n",
      "Epoch 6/150\n",
      "1050/1050 [==============================] - 3s 3ms/step - loss: 0.1284 - accuracy: 0.9476 - val_loss: 0.1353 - val_accuracy: 0.9370\n",
      "Epoch 7/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1165 - accuracy: 0.9528 - val_loss: 0.1170 - val_accuracy: 0.9502\n",
      "Epoch 8/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1183 - accuracy: 0.9518 - val_loss: 0.0944 - val_accuracy: 0.9629\n",
      "Epoch 9/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1128 - accuracy: 0.9542 - val_loss: 0.1020 - val_accuracy: 0.9590\n",
      "Epoch 10/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1085 - accuracy: 0.9561 - val_loss: 0.1034 - val_accuracy: 0.9530\n",
      "Epoch 11/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1044 - accuracy: 0.9566 - val_loss: 0.0956 - val_accuracy: 0.9642\n",
      "Epoch 12/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1017 - accuracy: 0.9577 - val_loss: 0.1163 - val_accuracy: 0.9526\n",
      "Epoch 13/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1031 - accuracy: 0.9575 - val_loss: 0.1936 - val_accuracy: 0.9056\n",
      "Epoch 14/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0989 - accuracy: 0.9597 - val_loss: 0.0980 - val_accuracy: 0.9580\n",
      "Epoch 15/150\n",
      "1050/1050 [==============================] - 3s 2ms/step - loss: 0.0959 - accuracy: 0.9594 - val_loss: 0.1091 - val_accuracy: 0.9527\n",
      "Epoch 16/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1106 - accuracy: 0.9554 - val_loss: 0.0820 - val_accuracy: 0.9620\n",
      "Epoch 17/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0977 - accuracy: 0.9600 - val_loss: 0.0810 - val_accuracy: 0.9688\n",
      "Epoch 18/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0905 - accuracy: 0.9621 - val_loss: 0.0959 - val_accuracy: 0.9588\n",
      "Epoch 19/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0939 - accuracy: 0.9613 - val_loss: 0.0724 - val_accuracy: 0.9714\n",
      "Epoch 20/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0958 - accuracy: 0.9619 - val_loss: 0.0829 - val_accuracy: 0.9658\n",
      "Epoch 21/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1308 - accuracy: 0.9497 - val_loss: 0.0998 - val_accuracy: 0.9627\n",
      "Epoch 22/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0922 - accuracy: 0.9605 - val_loss: 0.0790 - val_accuracy: 0.9655\n",
      "Epoch 23/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0882 - accuracy: 0.9638 - val_loss: 0.0742 - val_accuracy: 0.9692\n",
      "Epoch 24/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0914 - accuracy: 0.9621 - val_loss: 0.1280 - val_accuracy: 0.9537\n",
      "Epoch 25/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0942 - accuracy: 0.9615 - val_loss: 0.1663 - val_accuracy: 0.9737\n",
      "Epoch 26/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0884 - accuracy: 0.9641 - val_loss: 0.0957 - val_accuracy: 0.9631\n",
      "Epoch 27/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0795 - accuracy: 0.9670 - val_loss: 0.0954 - val_accuracy: 0.9585\n",
      "Epoch 28/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0777 - accuracy: 0.9678 - val_loss: 0.0681 - val_accuracy: 0.9738\n",
      "Epoch 29/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0811 - accuracy: 0.9658 - val_loss: 0.0901 - val_accuracy: 0.9612\n",
      "Epoch 30/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0823 - accuracy: 0.9652 - val_loss: 0.1139 - val_accuracy: 0.9511\n",
      "Epoch 31/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0848 - accuracy: 0.9652 - val_loss: 0.1706 - val_accuracy: 0.9502\n",
      "Epoch 32/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0991 - accuracy: 0.9599 - val_loss: 0.1174 - val_accuracy: 0.9482\n",
      "Epoch 33/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0775 - accuracy: 0.9676 - val_loss: 0.2282 - val_accuracy: 0.9715\n",
      "Epoch 34/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0917 - accuracy: 0.9639 - val_loss: 0.1227 - val_accuracy: 0.9660\n",
      "Epoch 35/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0799 - accuracy: 0.9669 - val_loss: 0.2595 - val_accuracy: 0.9721\n",
      "Epoch 36/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1417 - accuracy: 0.9610 - val_loss: 0.1576 - val_accuracy: 0.9354\n",
      "Epoch 37/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1009 - accuracy: 0.9579 - val_loss: 0.1316 - val_accuracy: 0.9477\n",
      "Epoch 38/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0790 - accuracy: 0.9676 - val_loss: 0.0747 - val_accuracy: 0.9693\n",
      "Epoch 39/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0858 - accuracy: 0.9639 - val_loss: 0.0693 - val_accuracy: 0.9746\n",
      "Epoch 40/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0792 - accuracy: 0.9657 - val_loss: 0.0703 - val_accuracy: 0.9740\n",
      "Epoch 41/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0922 - accuracy: 0.9638 - val_loss: 0.0819 - val_accuracy: 0.9657\n",
      "Epoch 42/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0699 - accuracy: 0.9709 - val_loss: 0.1440 - val_accuracy: 0.9419\n",
      "Epoch 43/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0977 - accuracy: 0.9635 - val_loss: 0.0903 - val_accuracy: 0.9648\n",
      "Epoch 44/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0758 - accuracy: 0.9685 - val_loss: 0.0817 - val_accuracy: 0.9694\n",
      "Epoch 45/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0824 - accuracy: 0.9660 - val_loss: 0.1118 - val_accuracy: 0.9706\n",
      "Epoch 46/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1001 - accuracy: 0.9630 - val_loss: 0.1730 - val_accuracy: 0.9249\n",
      "Epoch 47/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0825 - accuracy: 0.9661 - val_loss: 0.1063 - val_accuracy: 0.9542\n",
      "Epoch 48/150\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0742 - accuracy: 0.9696 - val_loss: 0.0761 - val_accuracy: 0.9656\n"
     ]
    }
   ],
   "source": [
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "tuned_model = tuner.hypermodel.build(best_hps)\n",
    "history = tuned_model.fit(X_train, y_train, epochs=150, callbacks=[early_stopping], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b252ea4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_22 (Dense)            (None, 192)               2496      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 192)               37056     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 192)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 192)               37056     \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 192)               37056     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 192)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 192)               37056     \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 192)               37056     \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 192)               0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 192)               37056     \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 192)               37056     \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 192)               0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 192)               37056     \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 96)                18528     \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 1)                 97        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 317,569\n",
      "Trainable params: 317,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tuned_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8d3f504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score       support\n",
      "0              0.982243  0.978306  0.980271  11478.000000\n",
      "1              0.962089  0.968875  0.965470   6522.000000\n",
      "accuracy       0.974889  0.974889  0.974889      0.974889\n",
      "macro avg      0.972166  0.973590  0.972870  18000.000000\n",
      "weighted avg   0.974940  0.974889  0.974908  18000.000000\n"
     ]
    }
   ],
   "source": [
    "y_pred = tuned_model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "report = classification_report(y_test,y_pred, output_dict = True)\n",
    "cr = pd.DataFrame(report).transpose()\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa437c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(\n",
    "    tuned_model, to_file='tuned_model.png', show_shapes=False, show_dtype=False,\n",
    "    show_layer_names=True, rankdir='LR', expand_nested=False, dpi=150,\n",
    "    layer_range=None, show_layer_activations=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac50b7d",
   "metadata": {},
   "source": [
    "# Droput Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e95b6aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1050/1050 [==============================] - 2s 1ms/step - loss: 0.4235 - accuracy: 0.7947 - val_loss: 0.2876 - val_accuracy: 0.8708\n",
      "Epoch 2/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.2702 - accuracy: 0.8775 - val_loss: 0.2366 - val_accuracy: 0.9020\n",
      "Epoch 3/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.2259 - accuracy: 0.9012 - val_loss: 0.2942 - val_accuracy: 0.8602\n",
      "Epoch 4/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1950 - accuracy: 0.9142 - val_loss: 0.1802 - val_accuracy: 0.9254\n",
      "Epoch 5/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1791 - accuracy: 0.9207 - val_loss: 0.1565 - val_accuracy: 0.9307\n",
      "Epoch 6/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1689 - accuracy: 0.9267 - val_loss: 0.2066 - val_accuracy: 0.9074\n",
      "Epoch 7/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1617 - accuracy: 0.9303 - val_loss: 0.1555 - val_accuracy: 0.9386\n",
      "Epoch 8/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1531 - accuracy: 0.9338 - val_loss: 0.1767 - val_accuracy: 0.9217\n",
      "Epoch 9/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1525 - accuracy: 0.9341 - val_loss: 0.2494 - val_accuracy: 0.8913\n",
      "Epoch 10/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1454 - accuracy: 0.9376 - val_loss: 0.1653 - val_accuracy: 0.9279\n",
      "Epoch 11/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1426 - accuracy: 0.9396 - val_loss: 0.1289 - val_accuracy: 0.9483\n",
      "Epoch 12/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1385 - accuracy: 0.9398 - val_loss: 0.1272 - val_accuracy: 0.9486\n",
      "Epoch 13/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1330 - accuracy: 0.9430 - val_loss: 0.1208 - val_accuracy: 0.9502\n",
      "Epoch 14/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1311 - accuracy: 0.9455 - val_loss: 0.1272 - val_accuracy: 0.9460\n",
      "Epoch 15/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1285 - accuracy: 0.9461 - val_loss: 0.1131 - val_accuracy: 0.9527\n",
      "Epoch 16/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1298 - accuracy: 0.9438 - val_loss: 0.1267 - val_accuracy: 0.9417\n",
      "Epoch 17/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1267 - accuracy: 0.9451 - val_loss: 0.1066 - val_accuracy: 0.9544\n",
      "Epoch 18/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1224 - accuracy: 0.9469 - val_loss: 0.1099 - val_accuracy: 0.9543\n",
      "Epoch 19/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1215 - accuracy: 0.9480 - val_loss: 0.1176 - val_accuracy: 0.9539\n",
      "Epoch 20/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1155 - accuracy: 0.9505 - val_loss: 0.1302 - val_accuracy: 0.9412\n",
      "Epoch 21/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1169 - accuracy: 0.9499 - val_loss: 0.1280 - val_accuracy: 0.9395\n",
      "Epoch 22/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1136 - accuracy: 0.9510 - val_loss: 0.1037 - val_accuracy: 0.9582\n",
      "Epoch 23/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1129 - accuracy: 0.9520 - val_loss: 0.1006 - val_accuracy: 0.9586\n",
      "Epoch 24/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1136 - accuracy: 0.9520 - val_loss: 0.1127 - val_accuracy: 0.9565\n",
      "Epoch 25/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1084 - accuracy: 0.9539 - val_loss: 0.1114 - val_accuracy: 0.9544\n",
      "Epoch 26/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1099 - accuracy: 0.9538 - val_loss: 0.1340 - val_accuracy: 0.9386\n",
      "Epoch 27/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1100 - accuracy: 0.9531 - val_loss: 0.0960 - val_accuracy: 0.9588\n",
      "Epoch 28/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1024 - accuracy: 0.9575 - val_loss: 0.1255 - val_accuracy: 0.9448\n",
      "Epoch 29/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1074 - accuracy: 0.9559 - val_loss: 0.1105 - val_accuracy: 0.9555\n",
      "Epoch 30/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1026 - accuracy: 0.9569 - val_loss: 0.1264 - val_accuracy: 0.9461\n",
      "Epoch 31/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1043 - accuracy: 0.9554 - val_loss: 0.1100 - val_accuracy: 0.9540\n",
      "Epoch 32/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1044 - accuracy: 0.9572 - val_loss: 0.0914 - val_accuracy: 0.9621\n",
      "Epoch 33/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0999 - accuracy: 0.9576 - val_loss: 0.1403 - val_accuracy: 0.9415\n",
      "Epoch 34/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1002 - accuracy: 0.9582 - val_loss: 0.0994 - val_accuracy: 0.9632\n",
      "Epoch 35/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1002 - accuracy: 0.9574 - val_loss: 0.0961 - val_accuracy: 0.9586\n",
      "Epoch 36/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0976 - accuracy: 0.9598 - val_loss: 0.0985 - val_accuracy: 0.9602\n",
      "Epoch 37/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1004 - accuracy: 0.9579 - val_loss: 0.1524 - val_accuracy: 0.9232\n",
      "Epoch 38/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1002 - accuracy: 0.9583 - val_loss: 0.0910 - val_accuracy: 0.9645\n",
      "Epoch 39/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0976 - accuracy: 0.9586 - val_loss: 0.1071 - val_accuracy: 0.9544\n",
      "Epoch 40/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0961 - accuracy: 0.9588 - val_loss: 0.0929 - val_accuracy: 0.9643\n",
      "Epoch 41/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0976 - accuracy: 0.9595 - val_loss: 0.0862 - val_accuracy: 0.9648\n",
      "Epoch 42/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0962 - accuracy: 0.9607 - val_loss: 0.1045 - val_accuracy: 0.9563\n",
      "Epoch 43/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0942 - accuracy: 0.9604 - val_loss: 0.1177 - val_accuracy: 0.9421\n",
      "Epoch 44/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0948 - accuracy: 0.9609 - val_loss: 0.1174 - val_accuracy: 0.9455\n",
      "Epoch 45/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0938 - accuracy: 0.9607 - val_loss: 0.1122 - val_accuracy: 0.9543\n",
      "Epoch 46/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0913 - accuracy: 0.9611 - val_loss: 0.1082 - val_accuracy: 0.9555\n",
      "Epoch 47/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0913 - accuracy: 0.9621 - val_loss: 0.1281 - val_accuracy: 0.9385\n",
      "Epoch 48/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0930 - accuracy: 0.9606 - val_loss: 0.0931 - val_accuracy: 0.9623\n",
      "Epoch 49/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0880 - accuracy: 0.9632 - val_loss: 0.1339 - val_accuracy: 0.9385\n",
      "Epoch 50/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0922 - accuracy: 0.9609 - val_loss: 0.0888 - val_accuracy: 0.9650\n",
      "Epoch 51/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0929 - accuracy: 0.9611 - val_loss: 0.1310 - val_accuracy: 0.9482\n",
      "Epoch 52/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0905 - accuracy: 0.9623 - val_loss: 0.0831 - val_accuracy: 0.9652\n",
      "Epoch 53/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0865 - accuracy: 0.9637 - val_loss: 0.0855 - val_accuracy: 0.9635\n",
      "Epoch 54/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0903 - accuracy: 0.9626 - val_loss: 0.0925 - val_accuracy: 0.9630\n",
      "Epoch 55/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0877 - accuracy: 0.9637 - val_loss: 0.0907 - val_accuracy: 0.9661\n",
      "Epoch 56/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0853 - accuracy: 0.9637 - val_loss: 0.0863 - val_accuracy: 0.9652\n",
      "Epoch 57/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0871 - accuracy: 0.9629 - val_loss: 0.0930 - val_accuracy: 0.9608\n",
      "Epoch 58/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0857 - accuracy: 0.9647 - val_loss: 0.0901 - val_accuracy: 0.9587\n",
      "Epoch 59/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0874 - accuracy: 0.9636 - val_loss: 0.0879 - val_accuracy: 0.9627\n",
      "Epoch 60/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0861 - accuracy: 0.9640 - val_loss: 0.0872 - val_accuracy: 0.9655\n",
      "Epoch 61/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0846 - accuracy: 0.9642 - val_loss: 0.0868 - val_accuracy: 0.9633\n",
      "Epoch 62/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0863 - accuracy: 0.9635 - val_loss: 0.1019 - val_accuracy: 0.9567\n",
      "Epoch 63/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0869 - accuracy: 0.9641 - val_loss: 0.0832 - val_accuracy: 0.9652\n",
      "Epoch 64/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0824 - accuracy: 0.9651 - val_loss: 0.0980 - val_accuracy: 0.9580\n",
      "Epoch 65/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0853 - accuracy: 0.9638 - val_loss: 0.0984 - val_accuracy: 0.9555\n",
      "Epoch 66/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0851 - accuracy: 0.9643 - val_loss: 0.1054 - val_accuracy: 0.9567\n",
      "Epoch 67/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0828 - accuracy: 0.9641 - val_loss: 0.0852 - val_accuracy: 0.9648\n",
      "Epoch 68/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0839 - accuracy: 0.9643 - val_loss: 0.0857 - val_accuracy: 0.9645\n",
      "Epoch 69/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0824 - accuracy: 0.9643 - val_loss: 0.0895 - val_accuracy: 0.9623\n",
      "Epoch 70/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0828 - accuracy: 0.9656 - val_loss: 0.0827 - val_accuracy: 0.9675\n",
      "Epoch 71/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0834 - accuracy: 0.9636 - val_loss: 0.0963 - val_accuracy: 0.9531\n",
      "Epoch 72/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0821 - accuracy: 0.9652 - val_loss: 0.1074 - val_accuracy: 0.9568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b753836280>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model_dropout = Sequential(\n",
    "    [\n",
    "        Dense(24 ,input_dim = 12, activation='relu'),\n",
    "        Dense(24 , activation='relu'),\n",
    "        Dropout(0.1, seed=42),\n",
    "        Dense(24 , activation='relu'),\n",
    "        Dense(24 , activation='relu'),\n",
    "        Dropout(0.1, seed=42),\n",
    "        Dense(24 , activation='relu'),\n",
    "        Dense(24 , activation='relu'),\n",
    "        Dropout(0.1, seed=42),\n",
    "        Dense(24 , activation='relu'),\n",
    "        Dense(24 , activation='relu'),\n",
    "        Dropout(0.1, seed=42),\n",
    "        Dense(24 , activation='relu'),\n",
    "        Dense(12 , activation='relu'),\n",
    "        Dense(1 , activation='sigmoid')\n",
    "    ]\n",
    ")\n",
    "\n",
    "mlp_model_dropout.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "mlp_model_dropout.fit(X_train,y_train,epochs = 150, callbacks=[early_stopping],validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22594c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_33 (Dense)            (None, 24)                312       \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 24)                600       \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 24)                0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 24)                600       \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 24)                600       \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 24)                0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 24)                600       \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 24)                600       \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 24)                0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 24)                600       \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 24)                600       \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 24)                0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 24)                600       \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 12)                300       \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp_model_dropout.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc483a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score       support\n",
      "0              0.963706  0.983185  0.973348  11478.000000\n",
      "1              0.969316  0.934836  0.951764   6522.000000\n",
      "accuracy       0.965667  0.965667  0.965667      0.965667\n",
      "macro avg      0.966511  0.959011  0.962556  18000.000000\n",
      "weighted avg   0.965739  0.965667  0.965528  18000.000000\n"
     ]
    }
   ],
   "source": [
    "y_pred = mlp_model_dropout.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "report = classification_report(y_test,y_pred, output_dict = True)\n",
    "cr = pd.DataFrame(report).transpose()\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d66925c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
